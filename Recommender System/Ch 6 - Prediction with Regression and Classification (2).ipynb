{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 파이썬으로 데이터마이닝 시작하기\n",
    "## 제 6 장 - 회귀와 분류를 이용한 예측\n",
    "### Copyright: Nathan Greeneltch, PhD 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "sns.set_context(\"paper\", font_scale=1.5)\n",
    "sns.set_style(\"white\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 회귀"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 회귀 예제 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모듈 임포트\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = fetch_california_housing(as_frame=True)\n",
    "ds_df = pd.DataFrame(ds.data, columns=ds.feature_names)\n",
    "print(ds.frame.columns)\n",
    "print(ds.data.columns)\n",
    "print(ds_df.columns)\n",
    "print(ds_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.frame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.target.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.frame.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 훈련/테스트 데이터로 나눠진 california_housing 데이터를 구하는 함수\n",
    "def get_california_housing():\n",
    "    # california_housing 데이터셋 불러오기\n",
    "    dataset = fetch_california_housing()\n",
    "    df = pd.DataFrame(dataset.data, columns=dataset.feature_names)\n",
    "    df['MedHouseVal'] = dataset.target\n",
    "    df.index.name = 'record'\n",
    "           \n",
    "    # 훈련 데이터셋과 테스트 데이터셋으로 나누기\n",
    "    X_train, X_test, y_train, y_test = \\\n",
    "        train_test_split(df.loc[:, df.columns != 'MedHouseVal'], \n",
    "                         df['MedHouseVal'], test_size=.33, random_state=42)\n",
    "\n",
    "    return [X_train, X_test, y_train, y_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 선형 회귀"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 선형 회귀 ###\n",
    "# 모듈 임포트\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# 훈련 데이터셋과 테스트 데이터셋으로 나누기\n",
    "X_train, X_test, y_train, y_test = get_california_housing()\n",
    "\n",
    "# 회귀 객체 초기화와 훈련 데이터에 대한 적합\n",
    "clf = LinearRegression()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# 테스트 데이터에서의 예측과 y_test에 대한 예측의 점수화\n",
    "y_pred = clf.predict(X_test)\n",
    "r2 = r2_score(y_test, y_pred) \n",
    "print('r2 score is = ' + str(r2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 패널티 회귀를 활용한 규제화(Regularization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 라쏘(Lasso) 회귀 ###\n",
    "# 모듈 임포트\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# 훈련 데이터셋과 테스트 데이터셋으로 나누기\n",
    "X_train, X_test, y_train, y_test = get_california_housing()\n",
    "\n",
    "# 분류기 객체 초기화와 훈련 데이터에 대한 적합\n",
    "clf = Lasso(alpha=0.3)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# 테스트 데이터 상에서의 예측과 y_test에 대한 예측 점수화\n",
    "y_pred = clf.predict(X_test)\n",
    "r2 = r2_score(y_test, y_pred) \n",
    "print('r2 score is = ' + str(r2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 릿지(Ridge) 회귀 ###\n",
    "# 모듈 임포트\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# 훈련 데이터셋과 테스트 데이터셋으로 나누기\n",
    "X_train, X_test, y_train, y_test = get_california_housing()\n",
    "\n",
    "# 분류기 객체 초기화와 훈련 데이터에 대한 적합\n",
    "clf = Ridge(alpha=0.3)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# 테스트 데이터 상에서의 예측과 y_test에 대한 예측 점수화\n",
    "y_pred = clf.predict(X_test)\n",
    "r2 = r2_score(y_test, y_pred) \n",
    "print('r2 score is = ' + str(r2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 분류(Classification)\n",
    "\n",
    "## 직관을 얻기 위한 분류기 예제 공부\n",
    "\n",
    "이 장의 나머지 부분에서는 예측에 사용되는 흔한 기법들을 다룰 것이다. 아래 그림은 다른 예측 기법들에 사용되는 여러 플롯들을 제시하고, 어떻게 그 플롯들이 입력 데이터를 타깃 변수에 매핑하는지를 보여준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image(\"compare_prediction_methods.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 분류 예제 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모듈 임포트\n",
    "from sklearn.datasets import make_moons\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 모의 moon 데이터를 얻기 위한 함수\n",
    "def get_moon_data():\n",
    "    # 데이터 모음을 생성하고 훈련 데이터와 테스트 데이터로 나누기\n",
    "    X, y = make_moons(n_samples=150, noise=0.4, random_state=42)\n",
    "    X_train, X_test, y_train, y_test = \\\n",
    "        train_test_split(X, y, test_size=.33, random_state=42)\n",
    "    \n",
    "    return [X_train, X_test, y_train, y_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 로지스틱 회귀(Logistic Regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 로지스틱 회귀 분류 ###\n",
    "# 모듈 임포트\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# moon 데이터 얻기\n",
    "X_train, X_test, y_train, y_test = get_moon_data()\n",
    "\n",
    "# 분류 객체 초기화와 훈련 데이터에 대한 적합\n",
    "clf = LogisticRegression(solver='lbfgs')\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# 테스트 데이터 상에서의 예측과 y_test에 대한 예측 점수화\n",
    "y_pred = clf.predict(X_test)\n",
    "f1 = f1_score(y_test, y_pred) \n",
    "print('f1 score is = ' + str(f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### confusion matrix ###\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "# confusion matrix 생성\n",
    "cm = confusion_matrix(y_pred, y_test) \n",
    "\n",
    "# 데이터프레임 생성과 클래스명 부여\n",
    "labels = ['top crescent', 'bottom cresent']\n",
    "df_cm = pd.DataFrame(cm,\n",
    "                     index = labels, \n",
    "                     columns = labels)\n",
    "\n",
    "# 플롯 규격 지정\n",
    "plt.figure(figsize=(5.5,4))\n",
    "sns.heatmap(df_cm, cmap=\"GnBu\", annot=True)\n",
    "\n",
    "# 제목과 축에 대한 레이블 부여\n",
    "plt.title('Logistic Regression \\nF1 Score:{0:.3f}'.format(f1_score(y_test, y_pred)))\n",
    "plt.ylabel('Prediction')\n",
    "plt.xlabel('Actual Class')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 규제화된 로지스틱 회귀(Regularized Logistic Regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 규제화된 로지스틱 회귀(Regularized Logistic Regression) ###\n",
    "clf = LogisticRegression(solver='lbfgs', penalty='l2', C=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 서포트 벡터 머신(Support Vector Machines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 서포트 벡터 머신 분류(SVM Classification) ###\n",
    "# 모듈 임포트\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# moon 데이터 얻기\n",
    "X_train, X_test, y_train, y_test = get_moon_data()\n",
    "\n",
    "# 분류 객체 초기화와 훈련 데이터에 대한 적합\n",
    "clf = SVC(kernel=\"linear\", C=0.5)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# 테스트 데이터 상에서의 예측과 y_test에 대한 예측 점수화\n",
    "y_pred = clf.predict(X_test)\n",
    "f1 = f1_score(y_test, y_pred) \n",
    "print('f1 score is = ' + str(f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 가우시안 커널 분류를 사용한 서포트 벡터 머신"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 가우시안 커널 분류를 사용한 서포트 벡터 머신 ###\n",
    "# 분류 객체 초기화와 훈련 데이터에 대한 적합\n",
    "clf = SVC(gamma=2, C=1)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# 테스트 데이터 상에서의 예측과 y_test에 대한 예측 점수화\n",
    "y_pred = clf.predict(X_test)\n",
    "f1 = f1_score(y_test, y_pred) \n",
    "print('f1 score is = ' + str(f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 트리 기반 분류\n",
    "\n",
    "### 의사결정 트리(Decision Tree Classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 의사결정 트리 분류(Decision Tree Classification) ###\n",
    "# 모듈 임포트\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# moon 데이터 얻기\n",
    "X_train, X_test, y_train, y_test = get_moon_data()\n",
    "\n",
    "# 분류 객체 초기화와 훈련 데이터에 대한 적합\n",
    "clf = DecisionTreeClassifier(max_depth=4, random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# 테스트 데이터 상에서의 예측과 y_test에 대한 예측 점수화\n",
    "y_pred = clf.predict(X_test)\n",
    "f1 = f1_score(y_test, y_pred) \n",
    "print('f1 score is = ' + str(f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 랜덤 포레스트(Random Forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 랜덤 포레스트 분류(Random Forest Classification) ###\n",
    "# 모듈 임포트\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# moon 데이터 얻기\n",
    "X_train, X_test, y_train, y_test = get_moon_data()\n",
    "\n",
    "# 분류 객체 초기화와 훈련 데이터에 대한 적합\n",
    "clf = RandomForestClassifier(max_depth=4, n_estimators=4, \n",
    "                             max_features='sqrt', random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# 테스트 데이터 상에서의 예측과 y_test에 대한 예측 점수화\n",
    "y_pred = clf.predict(X_test)\n",
    "f1 = f1_score(y_test, y_pred) \n",
    "print('f1 score is = ' + str(f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 랜덤 포레스트 모델의 검증을 위해 OOB 점수 사용하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 검증 데이터를 위한 OOB 사용 ###\n",
    "# 분류 객체 초기화와 훈련 데이터에 대한 적합\n",
    "clf = RandomForestClassifier(max_depth=4, n_estimators=10, \n",
    "                             max_features='sqrt', random_state=42,\n",
    "                             oob_score=True)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# OOB를 사용한 예측 점수화\n",
    "oob_score = clf.oob_score_\n",
    "print('OOB score is = ' + str(oob_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 교차 검증(Cross-validation)\n",
    "\n",
    "### 검증 데이터셋 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 교차 검증(Cross Validation) ###\n",
    "# iris 데이터 로딩과 X, y 생성\n",
    "from sklearn.datasets import load_iris\n",
    "dataset = load_iris()\n",
    "X,y = dataset.data, dataset.target\n",
    "\n",
    "# 모듈 임포트\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 훈련 및 테스트 데이터셋 생성\n",
    "X_train, X_test, y_train, y_test = \\\n",
    "        train_test_split(X, y, test_size=.33)\n",
    "\n",
    "# 훈련 데이터셋으로부터 검증 데이터셋 생성\n",
    "X_train, X_val, y_train, y_val = \\\n",
    "        train_test_split(X, y, test_size=.33)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### k-폴드 교차 검증(k-fold Cross-validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Metrics and Scoring\n",
    "* https://scikit-learn.org/stable/modules/model_evaluation.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### k-폴드 교차 검증(k-fold Cross Validation) ###\n",
    "# iris 데이터 로딩과 X, y 생성\n",
    "from sklearn.datasets import load_iris\n",
    "dataset = load_iris()\n",
    "X,y = dataset.data, dataset.target\n",
    "\n",
    "# 모듈 임포트\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 훈련 및 테스트 데이터셋 생성\n",
    "X_train, X_test, y_train, y_test = \\\n",
    "        train_test_split(X, y, test_size=.33)\n",
    "\n",
    "# 분류 객체 초기화 및 cross_val_score 함수에 전달\n",
    "clf = LogisticRegression(solver='lbfgs', multi_class='ovr')   # ovr: one vs (the rest) 방식\n",
    "scores = cross_val_score(clf, X_train, y_train, cv=5, scoring='f1_macro')\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 초매개변수 튜닝을 위한 그리드 검색(Grid Search for Hyperparamter Tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### k-폴드 교차 검증을 통한 그리드 검색 ###\n",
    "# iris 데이터 로딩과 X, y 생성\n",
    "from sklearn.datasets import load_iris\n",
    "dataset = load_iris()\n",
    "X,y = dataset.data, dataset.target\n",
    "\n",
    "# 모듈 임포트\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 훈련 및 테스트 데이터셋 생성\n",
    "X_train, X_test, y_train, y_test = \\\n",
    "        train_test_split(X, y, test_size=.33)\n",
    "\n",
    "# svc 및 그리드 검색 객체의 초기화와 적합 \n",
    "parameters = {'kernel':('linear', 'rbf'), 'C':[1, 5, 10]}\n",
    "svc = SVC(gamma='auto')\n",
    "clf = GridSearchCV(svc, parameters, cv=5, scoring='f1_macro')\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# 최상의 점수화 분류기 출력\n",
    "print('Best score is = ' + str(clf.best_score_))\n",
    "print('Best parameters are = ' + str(clf.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결과 분류기를 새로운 데이터 상에서 예측하는데 사용\n",
    "y_pred = clf.predict(X_test)\n",
    "y_pred"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
